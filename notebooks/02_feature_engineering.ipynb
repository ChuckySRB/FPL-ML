{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering & Data Preparation\n",
    "\n",
    "This notebook builds the training and test datasets for FPL points prediction.\n",
    "\n",
    "**Key design decisions:**\n",
    "- All rolling features use `shift(1)` to prevent data leakage (GW N only uses data from GW 1..N-1)\n",
    "- Training: 2022-23 season | Testing: 2023-24 season\n",
    "- Tier 1 features (~10) for Linear Regression baseline\n",
    "- Tier 2 features (~29) for XGBoost advanced model\n",
    "- Double gameweeks aggregated (stats summed per player-round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.preprocessing import (\n",
    "    FPLDataLoader, FPLFeatureEngineer, FPLPreprocessor,\n",
    "    TIER1_FEATURES, TIER2_FEATURES,\n",
    "    prepare_training_data, get_feature_columns_by_type\n",
    ")\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "pd.set_option('display.max_columns', 40)\n",
    "\n",
    "print('Setup complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = FPLDataLoader()\n",
    "\n",
    "# Load training season\n",
    "train_gw = loader.load_gameweeks('2022-23')\n",
    "train_teams = loader.load_teams('2022-23')\n",
    "train_fixtures = loader.load_fixtures('2022-23')\n",
    "\n",
    "# Load test season\n",
    "test_gw = loader.load_gameweeks('2023-24')\n",
    "test_teams = loader.load_teams('2023-24')\n",
    "test_fixtures = loader.load_fixtures('2023-24')\n",
    "\n",
    "print(f'Training (2022-23): {len(train_gw):,} records, {train_gw[\"element\"].nunique()} players')\n",
    "print(f'Testing  (2023-24): {len(test_gw):,} records, {test_gw[\"element\"].nunique()} players')\n",
    "print(f'\\nSample columns: {sorted(train_gw.columns.tolist())[:15]}...')\n",
    "print(f'Team dtype: {train_gw[\"team\"].dtype}, was_home dtype: {train_gw[\"was_home\"].dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick look at the raw data\n",
    "print('Target distribution (training):')\n",
    "print(train_gw['total_points'].describe())\n",
    "print(f'\\nPosition distribution:')\n",
    "print(train_gw['position_label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n",
    "\n",
    "**CRITICAL: Data leakage prevention**\n",
    "\n",
    "All rolling features are computed with `shift(1)`, meaning:\n",
    "- `form_last_3` at GW 10 = mean of total_points at GW 7, 8, 9 (NOT GW 10)\n",
    "- This ensures we only use past data when predicting future points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer = FPLFeatureEngineer()\n",
    "\n",
    "print('=== TRAINING DATA ===')\n",
    "train_feat = engineer.create_all_features(\n",
    "    train_gw, teams_df=train_teams, fixtures_df=train_fixtures, tier=2\n",
    ")\n",
    "\n",
    "print('\\n=== TEST DATA ===')\n",
    "test_feat = engineer.create_all_features(\n",
    "    test_gw, teams_df=test_teams, fixtures_df=test_fixtures, tier=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Verify No Data Leakage\n",
    "\n",
    "Let's verify with a known player that the shift works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify with Haaland (high-scoring player)\n",
    "haaland = train_feat[train_feat['name'].str.contains('Haaland', na=False)].sort_values('round')\n",
    "\n",
    "verify_cols = ['round', 'total_points', 'form_last_3', 'form_last_5', \n",
    "               'goals_last_5', 'minutes_last_3', 'was_home', 'opponent_difficulty']\n",
    "print('Haaland GW-by-GW (first 10):')\n",
    "print(haaland[verify_cols].head(10).to_string(index=False))\n",
    "\n",
    "# Manual verification\n",
    "gw1_pts = haaland.iloc[0]['total_points']\n",
    "gw2_pts = haaland.iloc[1]['total_points']\n",
    "expected_form = (gw1_pts + gw2_pts) / 2\n",
    "actual_form = haaland.iloc[2]['form_last_3']\n",
    "print(f'\\nVerification: GW1={gw1_pts}, GW2={gw2_pts}')\n",
    "print(f'  form_last_3 at GW3: expected={expected_form:.1f}, actual={actual_form:.1f}')\n",
    "print(f'  Match: {np.isclose(expected_form, actual_form)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Examine Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature distributions for Tier 2 features\n",
    "available_tier2 = [f for f in TIER2_FEATURES if f in train_feat.columns]\n",
    "\n",
    "# Drop early GWs for cleaner distributions\n",
    "sample = train_feat[train_feat['round'] >= 6]\n",
    "\n",
    "fig, axes = plt.subplots(5, 6, figsize=(20, 16))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feat in enumerate(available_tier2):\n",
    "    if i >= len(axes):\n",
    "        break\n",
    "    ax = axes[i]\n",
    "    vals = sample[feat].dropna()\n",
    "    ax.hist(vals, bins=50, alpha=0.7, edgecolor='black', linewidth=0.5)\n",
    "    ax.set_title(feat, fontsize=9, fontweight='bold')\n",
    "    ax.tick_params(labelsize=7)\n",
    "\n",
    "# Hide empty subplots\n",
    "for i in range(len(available_tier2), len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.suptitle('Tier 2 Feature Distributions (GW 6+)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Feature Correlations with Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation of features with total_points\n",
    "corr_data = train_feat[train_feat['round'] >= 6][available_tier2 + ['total_points']].copy()\n",
    "correlations = corr_data.corr()['total_points'].drop('total_points').sort_values(key=abs, ascending=False)\n",
    "\n",
    "print('Feature correlations with total_points:')\n",
    "print('=' * 50)\n",
    "for feat, corr in correlations.items():\n",
    "    bar = '+' * int(abs(corr) * 50)\n",
    "    print(f'  {feat:30s} {corr:+.4f} {bar}')\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlations.plot(kind='barh', color=['steelblue' if x > 0 else 'salmon' for x in correlations])\n",
    "plt.xlabel('Correlation with total_points')\n",
    "plt.title('Feature Correlations with Target', fontsize=14, fontweight='bold')\n",
    "plt.axvline(x=0, color='black', linewidth=0.5)\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Visualize Rolling Features for a Sample Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick Haaland for visualization\n",
    "player_data = train_feat[train_feat['name'].str.contains('Haaland', na=False)].sort_values('round')\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Points vs rolling averages\n",
    "ax = axes[0, 0]\n",
    "ax.plot(player_data['round'], player_data['total_points'], 'o-', alpha=0.5, label='Actual', ms=4)\n",
    "ax.plot(player_data['round'], player_data['form_last_3'], '-', lw=2, label='form_last_3')\n",
    "ax.plot(player_data['round'], player_data['form_last_5'], '-', lw=2, label='form_last_5')\n",
    "ax.set_title('Haaland: Points & Rolling Form (shifted)', fontweight='bold')\n",
    "ax.set_xlabel('Gameweek')\n",
    "ax.set_ylabel('Points')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# xG rolling\n",
    "ax = axes[0, 1]\n",
    "ax.plot(player_data['round'], player_data['expected_goals'], 'o-', alpha=0.5, label='xG (actual)', ms=4)\n",
    "ax.plot(player_data['round'], player_data['xG_last_5'], '-', lw=2, label='xG_last_5')\n",
    "ax.set_title('Haaland: Expected Goals', fontweight='bold')\n",
    "ax.set_xlabel('Gameweek')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Minutes\n",
    "ax = axes[1, 0]\n",
    "ax.bar(player_data['round'], player_data['minutes'], alpha=0.7, color='green')\n",
    "ax.axhline(90, color='red', ls='--', label='Full 90')\n",
    "ax.plot(player_data['round'], player_data['minutes_last_3'] , 'k-', lw=2, label='minutes_last_3')\n",
    "ax.set_title('Haaland: Minutes Played', fontweight='bold')\n",
    "ax.set_xlabel('Gameweek')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Opponent difficulty\n",
    "ax = axes[1, 1]\n",
    "colors = ['green' if h else 'red' for h in player_data['was_home']]\n",
    "ax.bar(player_data['round'], player_data['opponent_difficulty'], color=colors, alpha=0.7)\n",
    "ax.set_title('Haaland: Opponent Difficulty (green=home, red=away)', fontweight='bold')\n",
    "ax.set_xlabel('Gameweek')\n",
    "ax.set_ylabel('FDR')\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Training & Test Datasets\n",
    "\n",
    "Using the full pipeline: load -> engineer features -> select -> impute -> ready for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = FPLPreprocessor()\n",
    "\n",
    "# Build Tier 2 dataset (used for both models - Tier 1 is a subset)\n",
    "data = preprocessor.build_dataset(\n",
    "    train_seasons=['2022-23'],\n",
    "    test_season='2023-24',\n",
    "    tier=2,\n",
    "    min_gw=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train']\n",
    "y_test = data['y_test']\n",
    "\n",
    "print('Feature list:')\n",
    "print('=' * 60)\n",
    "tier1_available = [f for f in TIER1_FEATURES if f in X_train.columns]\n",
    "tier2_only = [f for f in data['feature_names'] if f not in TIER1_FEATURES]\n",
    "\n",
    "print(f'\\nTier 1 (Linear Regression baseline) - {len(tier1_available)} features:')\n",
    "for f in tier1_available:\n",
    "    print(f'  {f}')\n",
    "\n",
    "print(f'\\nTier 2 additions (XGBoost) - {len(tier2_only)} features:')\n",
    "for f in tier2_only:\n",
    "    print(f'  {f}')\n",
    "\n",
    "print(f'\\nTotal: {len(data[\"feature_names\"])} features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "print('SANITY CHECKS')\n",
    "print('=' * 60)\n",
    "print(f'NaN in X_train: {X_train.isnull().sum().sum()}')\n",
    "print(f'NaN in X_test: {X_test.isnull().sum().sum()}')\n",
    "print(f'NaN in y_train: {y_train.isnull().sum()}')\n",
    "print(f'NaN in y_test: {y_test.isnull().sum()}')\n",
    "print(f'\\nX_train shape: {X_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "print(f'\\ny_train: mean={y_train.mean():.2f}, std={y_train.std():.2f}, min={y_train.min()}, max={y_train.max()}')\n",
    "print(f'y_test:  mean={y_test.mean():.2f}, std={y_test.std():.2f}, min={y_test.min()}, max={y_test.max()}')\n",
    "print(f'\\nAll checks passed!' if X_train.isnull().sum().sum() == 0 else 'WARNING: NaN values remain!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train/Test Distribution Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Target distribution\n",
    "axes[0].hist(y_train, bins=range(-5, 25), alpha=0.7, label='Train (2022-23)', edgecolor='black', density=True)\n",
    "axes[0].hist(y_test, bins=range(-5, 25), alpha=0.5, label='Test (2023-24)', edgecolor='black', density=True)\n",
    "axes[0].set_title('Target Distribution', fontweight='bold')\n",
    "axes[0].set_xlabel('total_points')\n",
    "axes[0].set_ylabel('Density')\n",
    "axes[0].legend()\n",
    "\n",
    "# Dataset sizes\n",
    "axes[1].bar(['Train', 'Test'], [len(X_train), len(X_test)], color=['steelblue', 'orange'])\n",
    "axes[1].set_title('Dataset Sizes', fontweight='bold')\n",
    "axes[1].set_ylabel('Records')\n",
    "for i, v in enumerate([len(X_train), len(X_test)]):\n",
    "    axes[1].text(i, v + 200, f'{v:,}', ha='center', fontweight='bold')\n",
    "\n",
    "# Feature means comparison\n",
    "means = pd.DataFrame({\n",
    "    'Train': X_train.mean(),\n",
    "    'Test': X_test.mean()\n",
    "})\n",
    "means.plot(kind='barh', ax=axes[2], alpha=0.7)\n",
    "axes[2].set_title('Feature Means: Train vs Test', fontweight='bold')\n",
    "axes[2].set_xlabel('Mean Value')\n",
    "axes[2].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Position-Specific Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check target distribution by position\n",
    "train_full = data['train_df']\n",
    "test_full = data['test_df']\n",
    "\n",
    "print('Target stats by position (training):')\n",
    "print('=' * 60)\n",
    "for pos in ['GK', 'DEF', 'MID', 'FWD']:\n",
    "    pos_data = train_full[train_full['position_label'] == pos]['total_points']\n",
    "    print(f'  {pos:3s}: n={len(pos_data):5,}, mean={pos_data.mean():.2f}, '\n",
    "          f'std={pos_data.std():.2f}, max={pos_data.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position distribution visualization\n",
    "fig, axes = plt.subplots(1, 4, figsize=(18, 4))\n",
    "\n",
    "for i, pos in enumerate(['GK', 'DEF', 'MID', 'FWD']):\n",
    "    pos_train = train_full[train_full['position_label'] == pos]['total_points']\n",
    "    pos_test = test_full[test_full['position_label'] == pos]['total_points']\n",
    "    \n",
    "    axes[i].hist(pos_train, bins=range(-3, 20), alpha=0.7, label='Train', density=True)\n",
    "    axes[i].hist(pos_test, bins=range(-3, 20), alpha=0.5, label='Test', density=True)\n",
    "    axes[i].set_title(f'{pos} (n={len(pos_train):,})', fontweight='bold')\n",
    "    axes[i].set_xlabel('Points')\n",
    "    axes[i].legend(fontsize=8)\n",
    "\n",
    "plt.suptitle('Points Distribution by Position', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save datasets\n",
    "preprocessor.save(data, name='tier2_2022-23_to_2023-24')\n",
    "\n",
    "# Also save the full feature-engineered DataFrames for later analysis\n",
    "from configs.config import PROCESSED_DATA_DIR\n",
    "\n",
    "output_dir = PROCESSED_DATA_DIR / 'tier2_2022-23_to_2023-24'\n",
    "train_full.to_csv(output_dir / 'train_full.csv', index=False)\n",
    "test_full.to_csv(output_dir / 'test_full.csv', index=False)\n",
    "print(f'\\nFull DataFrames saved (for position-specific analysis later)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "### What was built:\n",
    "1. **Data Loader** - handles duplicate columns, team name-to-ID mapping, double GW aggregation\n",
    "2. **Feature Engineer** - 29 features across 2 tiers, all with `shift(1)` for no data leakage\n",
    "3. **Preprocessing Pipeline** - imputation, optional scaling, clean train/test split\n",
    "\n",
    "### Features created:\n",
    "| Tier | Feature | Description |\n",
    "|------|---------|-------------|\n",
    "| 1 | form_last_3, form_last_5 | Avg points in last 3/5 GWs |\n",
    "| 1 | minutes_last_3 | Avg minutes played |\n",
    "| 1 | was_home | Home (1) / Away (0) |\n",
    "| 1 | opponent_difficulty | FDR from fixtures.csv |\n",
    "| 1 | ict_index_last_3 | ICT index rolling avg |\n",
    "| 1 | price | Player cost / 10 |\n",
    "| 1 | pos_DEF/MID/FWD | Position one-hot |\n",
    "| 2 | goals/assists/cs_last_5 | Rolling stats |\n",
    "| 2 | xG/xA/xGC_last_5 | Expected stats rolling |\n",
    "| 2 | team/opponent_strength | From teams.csv |\n",
    "| 2 | cumulative_points_season | Season running total |\n",
    "\n",
    "### Data leakage prevention verified:\n",
    "- `form_last_3` at GW3 = mean(GW1, GW2) points only\n",
    "- GW1 has NaN for all rolling features (no prior data)\n",
    "- First 5 GWs dropped from training (incomplete rolling windows)\n",
    "\n",
    "### Next steps:\n",
    "- **Notebook 03**: Train Linear Regression (Tier 1 features)\n",
    "- **Notebook 04**: Train XGBoost (Tier 2 features)\n",
    "- **Notebook 05**: Compare models, evaluate against paper benchmarks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
